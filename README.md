# Prova Pr√°tica RNP
Este reposit√≥rio cont√©m a resolu√ß√£o das quest√µes da prova pr√°tica de DevOps da RNP.

# Quest√£o 1 - Op√ß√£o 1 de Implementa√ß√£o  

O c√≥digo aqui presente implementa a resolu√ß√£o para a quest√£o 1, que solicita uma aplica√ß√£o dockerizada que realize uma s√©rie de consultas de lat√™ncia, tempo de resposta e status HTTP da resposta. O c√≥digo em quest√£o foi elaborado em um sistema Linux Ubuntu 22.04.

## Estrutura b√°sica do c√≥digo 
A estrutura b√°sica do c√≥digo consiste das seguintes partes:

    agent/
        agent.py            --> script principal de consulta
        Dockerfile          --> montagem do container
        requirements.txt    --> requisitos da aplica√ß√£o
    secrets/                --> credenciais das plataformas
    grafana/                --> configura√ß√µes customizadas de consulta e dashboard
    docker-compose.yml      --> prepara√ß√£o de ambiente e containers

Ao executar o docker compose, ser√£o criados tr√™s containers executando: 
- InfluxDB (banco de dados escolhido)
- Grafana (para realizar a montagem dos dashboards)
- um agente python (quem realiza os pings e envia os dados ao InfluxDB)

Abaixo pode-se observar um fluxograma b√°sico do funcionamento do c√≥digo. Nele, **agent.py**, realiza as consultas aos sites e grava os resultados relevantes no **InfluxDB**. Esses dados ent√£o s√£o consultados pelo **Grafana** para exibir o Dashboard.

```mermaid
flowchart TD

    subgraph Agent["üü¶ agent.py"]
        A1["ping_host(host)"]
        A2["check_http(host)"]
        A3["Lat√™ncia, Status Code, Tempo de resposta"]
    end

    subgraph InfluxDB["üü© InfluxDB 2.x"]
        B1["Bucket: home"]
        B2["Measurement: network_metrics"]
        B3["Fields: ping_latency_ms, http_response_time_ms, http_status_code"]
        B4["Tags: host"]
    end

    subgraph Grafana["üüß Grafana"]
        C1["Realiza uma query 
        em Flux"]
        C2["Dashboard"]
        C3["Painel de Timeline do HTTP Status Code"]
        C4["Pain√©is de S√©rie Temporal"]
        C5["Lat√™ncia"]
        C6["RTT"]

    end
    subgraph Hosts["Internet"]
        D1["rnp.br"]
        D2["youtube.com"] 
        D3["google.com "]
    end
    Agent -->|Escreve os dados obtidos nas consultas no InfluxDB via client| InfluxDB
    Grafana -->|L√™ via Flux| InfluxDB
    Hosts -->|Resposta| A3

    A1 -->|Ping| Hosts
    A2 -->|Consulta HTTP| Hosts


    C1 --> C2
    C2 --> C3
    C2 --> C4
    C4 --> C5
    C4 --> C6
```


## Execu√ß√£o 
### Prerequisitos:
Ter o Docker instalado e Docker Compose
### Subindo os servi√ßos
Primeiramente clone o reposit√≥rio e acesse o diret√≥rio do projeto:

    git clone https://github.com/AlvaroLuz/entrevista-rnp
    cd entrevista-rnp

e inicialize o diret√≥rio *secrets/* com o *init_secrets.sh*

    sudo chmod +x init_secrets.sh #garantindo a permissao de execucao se nao houver
    sudo ./init_secrets.sh

ap√≥s isso, simplesmente suba os containers
    
    docker compose up -d

## Visualizando o Dashboard no Grafana
Ap√≥s subir os containers, √© esperado que o Grafana esteja rodando na porta 3000, portanto √© apenas necess√°rio acessar o link http://localhost:3000
    
**O perfil de Administrador do Grafana j√° estar√° configurado**, assim, as credenciais s√£o definidas automaticamente e a senha √© armazenada na pasta secrets usando o script de inicializa√ß√£o. 

> **username padr√£o: admin**

**para visualizar a senha**, apenas execute dentro da pasta do projeto:

    cat ./secrets/grafana_admin_password

uma vez logado no Grafana, entre na aba de **Dashboards**, nela estar√° configurado um Dashboard por padr√£o exibindo os dados coletados e armazenados no InfluxDB.

**OBS: na primeira vez que o Dashboard for carregado, ser√° necess√°rio clicar em editar e dar refresh em cada uma das consultas individualmente, devido a um bug do Grafana.**

# Quest√£o 2 -  **Outros Projetos Relevantes**

Grande parte do meu trabalho em DevOps foi desenvolvido dentro da infraestrutura da institui√ß√£o onde atuo atualmente, a Sala de Situa√ß√£o, um laborat√≥rio na UnB de pesquisas epidemiol√≥gicas, no qual atuo dentro da equipe de manuten√ß√£o da infraestrutura de TI. Portanto muitos dos meus projetos envolvem plataformas de sa√∫de, al√©m disso, alguns reposit√≥rios n√£o podem ser disponibilizados por conter dados sigilosos ou por conterem informa√ß√µes da nossa infraestrutura. Ainda assim, descrevo abaixo os principais tipos de projetos que desenvolvi e aponto reposit√≥rios p√∫blicos que representam de forma aproximada minha experi√™ncia.


---

### **Automa√ß√£o e Integra√ß√£o de Pipelines de Dados**

Tenho trabalhado extensivamente com automa√ß√£o de pipelines em Python, principalmente para integra√ß√£o entre APIs e coleta de dados em larga escala. Entre os projetos que desenvolvi internamente est√£o:

* Coleta e envio automatizado de dados do**Odoo** para o **Nextcloud**, usados por dashboards do Power BI.
* Pipelines de extra√ß√£o e tratamento de bases p√∫blicas de sa√∫de (**SINAN, SIA, CNES**).
* Extra√ß√£o peri√≥dica de dados do **Metabase** da plataforma Guardi√µes da Sa√∫de.

Os coletores desenvolvidos est√£o atualmente sendo adaptados para operarem de forma dockerizada, de forma a facilitar o trabalho de setup. O c√≥digo dessas implementa√ß√µes pode ser visto em:
    
    https://github.com/AlvaroLuz/repositorios-sds

---

### **Integra√ß√£o com Go.Data**

Desenvolvi uma integra√ß√£o em Python que processa dados nominais do **SINAN** (Sistema de Informa√ß√£o de Agravos de Notifica√ß√£o) e envia automaticamente para a plataforma **GoData** via **API**. O projeto envolve tratamento de dados, normaliza√ß√£o, logs estruturados. O c√≥digo fonte desse projeto pode ser visto em: 

    https://github.com/AlvaroLuz/sinan-godata-adapter

---

### **Implementa√ß√£o de sistema de backups Bacula e automa√ß√£o de instala√ß√£o para novos Hosts**

Implementei o sistema de backups utilizado pela instiu√ß√£o usando **Bacula**, tamb√©m implementei uma interface visual usando Bacularis para o monitoramento de nossos backups. Ainda, elaborei scripts shell que automatizam a instala√ß√£o e configura√ß√£o do cliente em novas m√°quinas. Esse trabalho reduziu significativamente o esfor√ßo manual para subir novos servidores e recuperar ambientes em casos de cat√°strofe.


---

### **Monitoramento com Zabbix**

Sou respons√°vel por parte da opera√ß√£o do nosso ambiente de monitoramento baseado em **Zabbix**, incluindo:

* Configura√ß√£o de hosts e templates
* Cria√ß√£o de gr√°ficos de monitoramento das atividades dos hosts ( Mem√≥ria, uso de CPU, Status do host) e gatilhos
* Monitoramento do espa√ßo para backup em nossa NAS e status dos clientes Bacula
* Ajustes em alertas via Telegram e a√ß√µes
* Inclus√£o cont√≠nua de novos servi√ßos e m√°quinas

Esse trabalho refor√ßa experi√™ncia pr√°tica com observabilidade e opera√ß√£o cont√≠nua.


---

### **Conclus√£o**

Como expliquei anteriormente, muitos dos projetos envolvem dados sens√≠veis e infraestrutura interna, n√£o posso disponibilizar os reposit√≥rios diretamente. No entanto, os exemplos acima refletem as √°reas onde atuo ativamente: automa√ß√£o, monitoramento e integra√ß√£o entre sistemas.



